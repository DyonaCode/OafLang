#!/usr/bin/env bash
set -euo pipefail

OUTPUT_PATH="${1:-benchmarks/CI_BENCHMARKS.md}"
BENCH_ITERATIONS="${BENCH_ITERATIONS:-100}"
KERNEL_ITERATIONS="${KERNEL_ITERATIONS:-5}"
SUM_N="${SUM_N:-5000000}"
PRIME_N="${PRIME_N:-30000}"
MATRIX_N="${MATRIX_N:-48}"
CROSS_LANG_ITERATIONS="${CROSS_LANG_ITERATIONS:-5}"

ROOT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/../.." && pwd)"
OUTPUT_FILE="${ROOT_DIR}/${OUTPUT_PATH}"

mkdir -p "$(dirname "${OUTPUT_FILE}")"

TMP_DIR="$(mktemp -d)"
trap 'rm -rf "${TMP_DIR}"' EXIT

BENCHMARK_OUTPUT="${TMP_DIR}/benchmark_output.txt"
KERNEL_OUTPUT="${TMP_DIR}/kernel_output.csv"
CROSS_LANG_STDOUT="${TMP_DIR}/cross_lang_output.txt"
CROSS_LANG_CSV="${TMP_DIR}/cross_lang.csv"

run_or_dump() {
  local label="$1"
  local output_file="$2"
  shift 2
  if ! "$@" > "${output_file}" 2>&1; then
    echo "[benchmark-report] ${label} failed. Captured output:" >&2
    cat "${output_file}" >&2 || true
    exit 1
  fi
}

run_or_dump "throughput benchmark" "${BENCHMARK_OUTPUT}" \
  dotnet run --configuration Release --no-build -- --benchmark "${BENCH_ITERATIONS}"

run_or_dump "kernel benchmark" "${KERNEL_OUTPUT}" \
  dotnet run --configuration Release --no-build -- --benchmark-kernels \
  --iterations "${KERNEL_ITERATIONS}" \
  --sum-n "${SUM_N}" \
  --prime-n "${PRIME_N}" \
  --matrix-n "${MATRIX_N}"

run_or_dump "cross-language benchmark" "${CROSS_LANG_STDOUT}" \
  bash ./scripts/benchmark/run_c_rust_benchmarks.sh \
  --iterations "${CROSS_LANG_ITERATIONS}" \
  --sum-n "${SUM_N}" \
  --prime-n "${PRIME_N}" \
  --matrix-n "${MATRIX_N}" \
  --oaf-mode all \
  --out "${CROSS_LANG_CSV}"

if [[ ! -s "${CROSS_LANG_CSV}" ]]; then
  echo "[benchmark-report] cross-language benchmark did not produce CSV output at ${CROSS_LANG_CSV}." >&2
  cat "${CROSS_LANG_STDOUT}" >&2 || true
  exit 1
fi

sanitize_output() {
  sed '/^CSSM_ModuleLoad()/d' "$1"
}

GENERATED_AT="$(date -u +"%Y-%m-%d %H:%M:%SZ")"
COMMIT_SHA="$(git -C "${ROOT_DIR}" rev-parse --short HEAD)"

cat > "${OUTPUT_FILE}" <<EOF
# CI Benchmark Report

This file is generated by \`.github/workflows/benchmark-report.yml\`.

- Generated (UTC): ${GENERATED_AT}
- Commit: \`${COMMIT_SHA}\`
- Runner OS: \`linux\`

## Throughput Benchmarks

Command:
\`\`\`bash
dotnet run --configuration Release --no-build -- --benchmark ${BENCH_ITERATIONS}
\`\`\`

\`\`\`text
$(sanitize_output "${BENCHMARK_OUTPUT}")
\`\`\`

## Kernel Benchmarks

Command:
\`\`\`bash
dotnet run --configuration Release --no-build -- --benchmark-kernels --iterations ${KERNEL_ITERATIONS} --sum-n ${SUM_N} --prime-n ${PRIME_N} --matrix-n ${MATRIX_N}
\`\`\`

\`\`\`csv
$(sanitize_output "${KERNEL_OUTPUT}")
\`\`\`

## Cross-Language Benchmarks (C, Rust, Oaf VM/Native, Oaf MLIR VM/Native)

Command:
\`\`\`bash
./scripts/benchmark/run_c_rust_benchmarks.sh --iterations ${CROSS_LANG_ITERATIONS} --sum-n ${SUM_N} --prime-n ${PRIME_N} --matrix-n ${MATRIX_N} --oaf-mode all
\`\`\`

Raw CSV:
\`\`\`csv
$(sanitize_output "${CROSS_LANG_CSV}")
\`\`\`

Relative to C baseline (mean_ms ratio):

| Algorithm | Rust/C | Oaf VM/C | Oaf Native/C | Oaf MLIR VM/C | Oaf MLIR Native/C |
|---|---:|---:|---:|---:|---:|
$(awk -F, '
NR == 1 { next }
{
  key = $2
  mean[$1, key] = $5 + 0.0
  alg[key] = 1
}
function ratio(numerator, denominator,   safe_denominator) {
  safe_denominator = denominator
  if (safe_denominator < 0.000001) {
    safe_denominator = 0.000001
  }
  return sprintf("%.3fx", numerator / safe_denominator)
}
END {
  for (key in alg) {
    if (!(("c", key) in mean)) {
      continue
    }
    c = mean["c", key]

    rust = (("rust", key) in mean) ? ratio(mean["rust", key], c) : "n/a"
    vm = (("oaf_vm", key) in mean) ? ratio(mean["oaf_vm", key], c) : "n/a"
    exe = (("oaf_exe", key) in mean) ? ratio(mean["oaf_exe", key], c) : "n/a"
    mlirVm = (("oaf_mlir_vm", key) in mean) ? ratio(mean["oaf_mlir_vm", key], c) : "n/a"
    mlirExe = (("oaf_mlir_exe", key) in mean) ? ratio(mean["oaf_mlir_exe", key], c) : "n/a"
    printf "| %s | %s | %s | %s | %s | %s |\n", key, rust, vm, exe, mlirVm, mlirExe
  }
}' "${CROSS_LANG_CSV}" | sort)

Oaf mode comparison (mean_ms ratio):

| Algorithm | VM/Native | MLIR VM/VM | MLIR Native/Native | MLIR VM/MLIR Native |
|---|---:|---:|---:|---:|
$(awk -F, '
NR == 1 { next }
$1 ~ /^oaf_/ {
  mean[$1, $2] = $5 + 0.0
  alg[$2] = 1
}
function ratio(numerator, denominator,   safe_denominator) {
  safe_denominator = denominator
  if (safe_denominator < 0.000001) {
    safe_denominator = 0.000001
  }
  return sprintf("%.3fx", numerator / safe_denominator)
}
END {
  for (key in alg) {
    vm = (("oaf_vm", key) in mean && ("oaf_exe", key) in mean) ? ratio(mean["oaf_vm", key], mean["oaf_exe", key]) : "n/a"
    mlirVm = (("oaf_mlir_vm", key) in mean && ("oaf_vm", key) in mean) ? ratio(mean["oaf_mlir_vm", key], mean["oaf_vm", key]) : "n/a"
    mlirNative = (("oaf_mlir_exe", key) in mean && ("oaf_exe", key) in mean) ? ratio(mean["oaf_mlir_exe", key], mean["oaf_exe", key]) : "n/a"
    mlirVmVsNative = (("oaf_mlir_vm", key) in mean && ("oaf_mlir_exe", key) in mean) ? ratio(mean["oaf_mlir_vm", key], mean["oaf_mlir_exe", key]) : "n/a"
    printf "| %s | %s | %s | %s | %s |\n", key, vm, mlirVm, mlirNative, mlirVmVsNative
  }
}' "${CROSS_LANG_CSV}" | sort)

## Notes

- Values can fluctuate between runs due to shared CI runner variability.
- Treat this report as trend/reference data, not a strict performance guarantee.
EOF
